---
output: 
  html_document: 
    keep_md: yes
---
STA 380, Part 2: Exercises 1
============================

Exploratory Analysis on Vote Undercount in Georgia
---------------------------------------------------
The following investigates the issue of vote undercount in Georgia for the 2000 presidential election using data from 159 counties. Undercount is defined as the difference between the number of ballots cast and the number of legal votes recorded.

The analysis below will illuminate two issues: (1) whether voting certain kinds of voting equipment lead to higher rates of undercount, and (2) if so, whether we should worry that this effect has a disparate impact on poor and minority communities.
```{r}
# Import data
setwd("C:/Users/Julia Wu/Desktop/Predictive Models 2/STA380/data")
georgia = read.csv("georgia2000.csv")
```

```{r}
# Calculate the percent of votes that were undercounted
georgia$percent_undercount <- (georgia$ballots - georgia$votes)/georgia$ballots
```
The boxplot shows median undercount percentages to be fairly consistent across voting equipment, with the median for punch card being slightly higher. There are 5 outliers above the maximum - 1 for lever and 4 for optical. The outliers for optical are interesting as they indicate particularly high undercount percentages in 4 counties. These outliers are likely the result of factors outside of the voting equipment used.
```{r}
# Make a boxplot of voting equipment and undercount
boxplot(percent_undercount~equip, data=georgia, main="Undercount by Equip", xlab="Voting Equipment", ylab="Percent Undercount")
```

```{r}
# Check variables in georgia
head(georgia, 2)

# Remove county, ballots, and votes
georgia = georgia[,c(-1,-2,-3)]
```
Running a multiple linear regression reveals a strong and positive relationship between equipOPTICAL and percent_undercount with a regression coefficient of 1.381e-02 and a t-value of 3.412. EquipPUNCH is also a strong predictor of percent_undercount with a regression coefficient of 1.424e-02 and a t-value of 2.128. The results indicate that voting with punch cards and optical scans results in higher undercount percentages.

The regression output is consistent with our observations from the box plot as punch cards tend to have higher undercount percentages than the other voting equipment do. Likewise, the relationship between equipOPTICAL and percent_undercount was probably in large due to the outliers we saw.
```{r}
# Run a multiple linear regression predicting undercount
lm.georgia = lm(percent_undercount~., data=georgia)
summary(lm.georgia)
```
Plotting poor and equip reveals that poor counties use optical scans and punch cards less frequently than non-poor counties do. Therefore the impact of higher undercount percentages will be on non-poor counties.
```{r}
# Plot equip against poor, perAA, and urban
plot(georgia$equip~georgia$poor, xlab = "Poor", ylab = "Equip")
```

Plotting equip and perAA shows that counties with high African American populations use optical scans less frequently and punch cards more frequently than counties with low African American populations do. Therefore undercount percentages in counties with high African American populations will be affected by their punch card usage.
```{r}
plot(georgia$equip~georgia$perAA, xlab = "PerAA", ylab = "Equip")
```


Evaluating ETF Portfolios with Bootstrapping
--------------------------------------------
In the following, bootstrap resampling will be used to estimate the 4-week (20-trading day) value at risk of 3 portfolios at the 5% level. An evenly split portfolio, a safe/risk averse portfolio, and an aggressive/risk seeking portfolio will be assessed. These portfolios will be composed of 5 ETFs - SPY, TLT, LQD, EEM, and VNQ. 
```{r results='hide', message=FALSE, warning=FALSE}
# Import libraries
library(mosaic)
library(fImport)
library(foreach)
```

```{r}
# Import five years of daily data on ETFs SPY, TLT, LQD, EEM, and VNQ
funds = c("SPY", "TLT", "LQD", "EEM", "VNQ")
prices = yahooSeries(funds, from='2009-01-01', to='2014-12-31')

# Add helper function for calculating percent returns from Yahoo Series
YahooPricesToReturns = function(series) {
	mycols = grep('Adj.Close', colnames(series))
	closingprice = series[,mycols]
	N = nrow(closingprice)
	percentreturn = as.data.frame(closingprice[2:N,]) / as.data.frame(closingprice[1:(N-1),]) - 1
	mynames = strsplit(colnames(percentreturn), '.', fixed=TRUE)
	mynames = lapply(mynames, function(x) return(paste0(x[1], ".PctReturn")))
	colnames(percentreturn) = mynames
	as.matrix(na.omit(percentreturn))
}

# Compute the returns from the closing prices
returns = YahooPricesToReturns(prices)
head(returns,2)

# Plot returns for each ETF and assess risk and return
plot(returns[,1], type='l', main='SPY')
plot(returns[,2], type='l', main='TLT')
plot(returns[,3], type='l', main='LQD')
plot(returns[,4], type='l', main='EEM')
plot(returns[,5], type='l', main='VNQ')
```

VNQ and EEM have the highest standard devations of 0.020 and 0.017, respectively. These ETFs will be classified as 'risky'. SPY and TLT have lower standard deviations of 0.011 and 0.010 and will be classified as 'medium'. LQD has low return and the lowest standard deviation of 0.004 and will be classified as 'safe'.

Risky - VNQ: mean=0.09%, sd=0.020, EEM: mean=0.05%, sd=0.017  
Medium - SPY: mean=0.07%, sd=0.011, TLT: mean=0.02%, sd=0.010  
Safe - LQD: mean=0.03%, sd=0.004
```{r}
# Calculate and assess the mean and standard deviation of daily returns for each ETF
mu_SPY = mean(returns[,1])
sigma_SPY = sd(returns[,1])
mu_TLT = mean(returns[,2])
sigma_TLT = sd(returns[,2])
mu_LQD = mean(returns[,3])
sigma_LQD = sd(returns[,3])
mu_EEM = mean(returns[,4])
sigma_EEM = sd(returns[,4])
mu_VNQ = mean(returns[,5])
sigma_VNQ = sd(returns[,5])
```
4 weeks of return is simulated using bootstrap for an evenly split portfolio - 20% weight in each ETF.
```{r}
# Perform bootstrap 5000 times for even split portfolio
n_days = 20
set.seed(1234567)
sim_even = foreach(i=1:5000, .combine='rbind') %do% {
	totalwealth = 100000
	weights = c(0.2, 0.2, 0.2, 0.2, 0.2)
	holdings = weights * totalwealth
	wealthtracker = rep(0, n_days)
	for(today in 1:n_days) {
		return.today = resample(returns, 1, orig.ids=FALSE)
		holdings = holdings + holdings*return.today
		totalwealth = sum(holdings)
		wealthtracker[today] = totalwealth
		holdings = weights * totalwealth
	}
	wealthtracker
}
```
4 weeks of return is simulated using bootstrap for a "safe" portfolio - 20% weight on medium risk ETFs SPY and TLT, 60% weight on safe ETF LQD.
```{r}
# Perform bootstrap 5000 times for safe portfolio - 20% SPY, 20% TLT, 60% LQD
set.seed(1234567)
sim_safe = foreach(i=1:5000, .combine='rbind') %do% {
	totalwealth = 100000
	weights = c(0.2, 0.2, 0.6, 0.0, 0.0)
	holdings = weights * totalwealth
	wealthtracker = rep(0, n_days)
	for(today in 1:n_days) {
		return.today = resample(returns, 1, orig.ids=FALSE)
		holdings = holdings + holdings*return.today
		totalwealth = sum(holdings)
		wealthtracker[today] = totalwealth
		holdings = weights * totalwealth
	}
	wealthtracker
}
```
4 weeks of return is simulated using bootstrap for an "aggressive" portfolio - 20% weight on risky ETF EEM, 80% weight on risky ETF VNQ.
```{r}
# Perform bootstrap 5000 times for aggressive portfolio - 20% EEM, 80% VNQ
set.seed(1234567)
sim_aggressive = foreach(i=1:5000, .combine='rbind') %do% {
	totalwealth = 100000
	weights = c(0.0, 0.0, 0.0, 0.2, 0.8)
	holdings = weights * totalwealth
	wealthtracker = rep(0, n_days)
	for(today in 1:n_days) {
		return.today = resample(returns, 1, orig.ids=FALSE)
		holdings = holdings + holdings*return.today
		totalwealth = sum(holdings)
		wealthtracker[today] = totalwealth
		holdings = weights * totalwealth
	}
	wealthtracker
}
```

```{r}
# Compute average portfolio values of the 5000 simulations for each portfolio
avg_evensplit_return = mean(sim_even[,n_days])
avg_safe_return = mean(sim_safe[,n_days])
avg_aggressive_return = mean(sim_aggressive[,n_days])
```
Plotting the average 4-week returns for each portfolio type reveals that the aggressive portfolio yields the highest return on average followed by the even split portfolio and the safe portfolio.  
The even split portfolio yields `r round((avg_evensplit_return - 100000)/100000,3)` on average.  
The safe portfolio yields `r round((avg_safe_return - 100000)/100000,3)` on average.  
The aggressive portfolio yields `r round((avg_aggressive_return - 100000)/100000,3)` on average.
```{r}
# Plot the average portfolio values for each portfolio
plot(c(1,20), c(100000,avg_evensplit_return), type='l', col='#009E73', lwd=2, ylim=c(100000,103000), xlab='Days', ylab='Portfolio Value', main="Average 4-week return by Portfolio Type")
lines(c(1,20), c(100000, avg_safe_return),type='l', col='#56B4E9', lwd=2)
lines(c(1,20), c(100000,avg_aggressive_return), type='l', col='#E69F00', lwd=2)
legend('topright', c('Aggressive','Even Split','Safe'), col=c('#E69F00','#009E73','#56B4E9'), lwd=2, bty='n')
```

However, the 4-week value at risk at the 5% level is `r sprintf("$ %3.2f", quantile(sim_even[,n_days], 0.05) - 100000)` for the even split portfolio, `r sprintf("$ %3.2f", quantile(sim_safe[,n_days], 0.05) - 100000)` for the safe portfolio, and `r sprintf("$ %3.2f", quantile(sim_aggressive[,n_days], 0.05) - 100000)` for the risky portfolio. Thus, the potential for greater returns comes at the cost of higher risk.
```{r}
# Calculate value at risk aat the 5% level for each portfolio
quantile(sim_even[,n_days], 0.05) - 100000
quantile(sim_safe[,n_days], 0.05) - 100000
quantile(sim_aggressive[,n_days], 0.05) - 100000

# Graph the return distribution for each portfolio
hist(sim_even[,n_days] - 100000, xlab='Portfolio Value', main='Distribution of Even Split Portfolio Returns')
hist(sim_safe[,n_days] - 100000, xlab='Portfolio Value', main='Distribution of Safe Portfolio Returns')
hist(sim_aggressive[,n_days]- 100000, xlab='Portfolio Value', main='Distribution of Aggressive Portfolio Returns')
```


Distinguishing Wines with Clustering and PCA
--------------------------------------------
Using data on 11 chemical properties of 6500 different bottles of vinho verde wine from northern Portugal, we will attempt to distinguish wine color and quality with clustering and principle component analysis.
```{r results='hide', message=FALSE, warning=FALSE}
# Import libraries
library(ggplot2)
```

```{r}
# Import data
setwd("C:/Users/Julia Wu/Desktop/Predictive Models 2/STA380/data")
wine = read.csv("wine.csv")

# Check variables in wine
head(wine, 2)

# Remove quality and color
wine2 = wine[,1:11]
```
Run hierarchial clustering to distinguish red wines from white wines.
```{r}
# Center/scale the data
wine2_scaled <- scale(wine2, center=TRUE, scale=TRUE)

# Form a pairwise distance matrix using the dist function
wine2_distance_matrix = dist(wine2_scaled, method='euclidean')

# Run hierarchical clustering
hier_wine2 = hclust(wine2_distance_matrix, method='complete')

# Cut the tree into 10 clusters
cluster1 = cutree(hier_wine2, k=10)
summary(factor(cluster1))
```
Reds and whites are separated fairly well across clusters except for cluster 2.
```{r}
# Examine the cluster members
summary(wine$color[which(cluster1 == 1)])
summary(wine$color[which(cluster1 == 2)])
summary(wine$color[which(cluster1 == 3)])
summary(wine$color[which(cluster1 == 4)])
summary(wine$color[which(cluster1 == 5)])
summary(wine$color[which(cluster1 == 6)])
summary(wine$color[which(cluster1 == 7)])
summary(wine$color[which(cluster1 == 8)])
summary(wine$color[which(cluster1 == 9)])
summary(wine$color[which(cluster1 == 10)])
```
Run principal component analysis to distinguish red wines from white wines
```{r}
pc1 = prcomp(wine2, scale.=TRUE)
plot(pc1, main='Variance by PC')
```

PCA did well in distinguishing red wines from white wines. The plot shows two clear clusters separating reds from whites with only very few whites in the red cluster. It appears that PCA does better in distinguishing wine color than hierarchial clustering does.
```{r}
scores = pc1$x
qplot(scores[,1], scores[,2], color=wine$color, xlab='Component 1', ylab='Component 2')
```

Color coding the scores by quality, we see that some quality scores are centered around the same area, but the relationships aren't as clear. PCA isn't as effective in classifying wine quality. 
```{r}
qplot(scores[,1], scores[,2], color=as.factor(wine$quality), xlab='Component 1', ylab='Component 2')
```


Market Segmentation with PCA
----------------------------
The following uses principle component analysis to identify market segments using data from a large consumer brand's twitter following. Each row of data represents a twitter follower and the number of tweets they had related to a particular topic of interest. The segments are groups of interests that appear to stand out in the company's social-media audience.
```{r results='hide', message=FALSE, warning=FALSE}
# Import libraries
library(flexclust)
library(ggplot2)
```

```{r}
# Import data
setwd("C:/Users/Julia Wu/Desktop/Predictive Models 2/STA380/data")
social = read.csv("social_marketing.csv",header=TRUE,row.names=1)

# Check variables in social
head(social, 2)

# Remove chatter, uncategorized, spam, and adult
social = social[,c(-1,-5,-35,-36)]
```

```{r}
# Normalize phrase counts to phrase frequencies as a percentage
social_freq = social/rowSums(social)

# Run PCA
pc2 = prcomp(social_freq, scale=TRUE)
loadings = pc2$rotation
scores = pc2$x
plot(pc2, main='Variance by PC')
```

We will consider up to PC7 since standard deviation drops to 1.08 at PC8. The 4 highest loadings for each PC up to PC7 will be used to define a market segment.
```{r}
summary(pc2)
# Order the loadings ascending
o1 = order(loadings[,1])
o2 = order(loadings[,2])
o3 = order(loadings[,3])
o4 = order(loadings[,4])
o5 = order(loadings[,5])
o6 = order(loadings[,6])
o7 = order(loadings[,7])
o8 = order(loadings[,8])

# Return the top 4 variables with the highest loadings for each PC
colnames(social_freq)[tail(o1,4)]
colnames(social_freq)[tail(o2,4)]
colnames(social_freq)[tail(o3,4)]
colnames(social_freq)[tail(o4,4)]
colnames(social_freq)[tail(o5,4)]
colnames(social_freq)[tail(o6,4)]
colnames(social_freq)[tail(o7,4)]
```

